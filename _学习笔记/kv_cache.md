#                               **kv cache**

+ ### èƒŒæ™¯ï¼š

  `causalLM` æ¨¡å‹é‡‡ç”¨è‡ªå›å½’ï¼ˆ`auto_regressive`ï¼‰çš„æ–¹æ³•ï¼Œåœ¨æ¨ç†è¿‡ç¨‹é€šå¸¸åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š**prefillå’Œdecode**ã€‚**é€šå¸¸ä¼šä½¿ç”¨KV cacheæŠ€æœ¯å­˜å‚¨å·²å®Œæˆè®¡ç®—çš„ä¿¡æ¯(æ¯å±‚æ¯å¤´kï¼Œv), åŠ é€Ÿæ¨ç†**ã€‚

  <img src="./assets/kv_cache/kv_cache.png" style="zoom: 70%;" />

  + **Prefill**:

    **é¢„å¡«å……é˜¶æ®µ**: æŠŠæ•´æ®µ`prompt`å–‚ç»™æ¨¡å‹åš`forward`è®¡ç®—ã€‚å¦‚æœé‡‡ç”¨`KV cache`æŠ€æœ¯ï¼Œè¿™ä¸ªé˜¶æ®µä¸­ä¼šæŠŠ`prompt `è¿‡ $ W_k $ï¼Œ$W_v$  åå¾—åˆ°çš„$X_k$ï¼Œ$X_v$â€‹ ä¿å­˜åœ¨**cache_kå’Œcache_v**ä¸­ï¼Œè¿™æ ·åœ¨å¯¹åé¢çš„ `token` è®¡ç®— `attention` æ—¶ï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦å¯¹å‰é¢çš„ `token` é‡å¤è®¡ç®—$X_k$ï¼Œ$X_v$ï¼Œå¤§å¹…åº¦èŠ‚çœæ¨ç†æ—¶é—´ã€‚

    <img src="./assets/kv_cache/prefill.png" style="zoom:85%;" />

    

  + **Decodeï¼š**

    åœ¨è¿™ä¸ªé˜¶æ®µä¸­ï¼Œ**æ ¹æ®promptçš„prefillç»“æœï¼Œä¸€ä¸ªtokenä¸€ä¸ªtokenåœ°ç”Ÿæˆresponseã€‚**åŒæ ·ï¼Œå¦‚æœé‡‡ç”¨äº†`KV cache`ï¼Œåˆ™æ¯èµ°å®Œä¸€ä¸ª`decode`è¿‡ç¨‹ï¼Œæˆ‘ä»¬å°±æŠŠå¯¹åº”`response token`çš„KVå€¼å­˜å…¥`cache`ä¸­ï¼Œä»¥ä¾¿èƒ½åŠ é€Ÿè®¡ç®—ã€‚

    **ç”±äº`Decode`é˜¶æ®µçš„æ˜¯é€ä¸€ç”Ÿæˆ`token`çš„ï¼Œå› æ­¤å®ƒä¸èƒ½åƒprefillé˜¶æ®µé‚£æ ·èƒ½åšå¤§æ®µ`prompt`çš„å¹¶è¡Œè®¡ç®—ï¼Œæ‰€ä»¥åœ¨LLMæ¨ç†è¿‡ç¨‹ä¸­ï¼ŒDecodeé˜¶æ®µçš„è€—æ—¶ä¸€èˆ¬æ˜¯æ›´å¤§çš„ã€‚**

    <img src="./assets/kv_cache/decoder.png" style="zoom:50%;" />

    è®¾è¾“å…¥åºåˆ—çš„é•¿åº¦ä¸º $s$ ï¼Œè¾“å‡ºåºåˆ—çš„é•¿åº¦ä¸º$ n$ ï¼Œæ¨¡å‹æ·±åº¦ä¸º$l$ï¼Œç»´åº¦ä¸º$h$,ä»¥ FP16 æ¥ä¿å­˜KV cacheï¼Œé‚£ä¹ˆKV cacheçš„å³°å€¼æ˜¾å­˜å ç”¨å¤§å°ä¸º $b(s+n)hâˆ—lâˆ—2âˆ—2=4blh(s+n)$ ã€‚
    
    æ¨¡å‹è¶Šå¤§ï¼ŒKV cacheæ‰€æ¶ˆè€—æ˜¾å­˜å°±è¶Šå¤§ã€‚ç”±äºLLMæ¨ç†é€Ÿåº¦æ˜¯ç”±`è®¡ç®—flops`ï¼Œ`æ˜¾å­˜ã€å¸¦å®½` å…±åŒå†³å®šçš„ï¼Œå³æœ‰è®¡ç®—å’Œé€šä¿¡æ—¶é—´ç»„æˆã€‚å¦‚æœèƒ½å‹ç¼©`kv_cache`, å‡è½»è´Ÿè½½å‹åŠ›(GPUæ˜¾å­˜ä¼ è¾“ç‰‡ä¸ŠRAM)ï¼Œèƒ½æå‡æ¨ç†é€Ÿåº¦ï¼Œå¹¶åŒæ—¶å¯ä»¥å¤„ç†æ›´å¤šbatchï¼Œå¢åŠ ååé‡ã€‚
    
    
    
    ä»ä¸Šè¿°è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°ä½¿ç”¨KV cacheåšæ¨ç†æ—¶çš„ä¸€äº›ç‰¹ç‚¹ï¼š
    
    - **éšç€promptæ•°é‡å˜å¤šå’Œåºåˆ—å˜é•¿ï¼ŒKV cacheä¹Ÿå˜å¤§ï¼Œå¯¹gpuæ˜¾å­˜é€ æˆå‹åŠ›**
    - **ç”±äºè¾“å‡ºçš„åºåˆ—é•¿åº¦æ— æ³•é¢„å…ˆçŸ¥é“ï¼Œå¾ˆéš¾æå‰ä¸ºKV cacheé‡èº«å®šåˆ¶å­˜å‚¨ç©ºé—´,è§vLLM**

  ******

+ ### å†…å­˜ç®¡ç†ï¼š

  ä¸‹å›¾å±•ç¤ºäº†ä¸€ä¸ª13Bçš„æ¨¡å‹åœ¨ A100 40GB çš„ gpuä¸Šåšæ¨ç†æ—¶çš„æ˜¾å­˜å ç”¨åˆ†é…ï¼Œothersè¡¨ç¤ºforwardè¿‡ç¨‹ä¸­äº§ç”Ÿçš„æ¿€æ´»å€¼(activationï¼‰çš„å¤§å°ã€‚

  <img src="./assets/kv_cache/A100.png" style="zoom:50%;" />

  + **æ–¹å¼1ï¼šé‡åŒ–å‚æ•°**

    ä¸»æµä¸¤ç§é‡åŒ–ï¼šåè®­ç»ƒé‡åŒ–(PTQ)å’Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(QAT)ï¼Œ å‰è€…ä»£è¡¨ä½œï¼š`GPTQ`, `AWQ`, åè€…ä»£è¡¨ä½œ`QLORA`,  æœ¬æ–‡ä¸èšç„¦ã€‚

  + **æ–¹å¼2ï¼šä¼˜åŒ–KV**

    è°ƒæ•´æ¨¡å‹ç»“æ„å‹ç¼©`kv_cache` ç¼“å­˜ï¼Œæé«˜æ¨ç†ååé‡ã€‚



+ ### kv cache

  + **å·¥ç¨‹ä¸Šä¼˜åŒ–**: **vLLMé€šè¿‡ PagedAttention çš„æŠ€æœ¯ï¼ŒåŠ¨æ€åœ°ä¸ºè¯·æ±‚åˆ†é…KV cacheæ˜¾å­˜ï¼Œæå‡æ˜¾å­˜åˆ©ç”¨ç‡ã€‚**

  + **`MHA` æ–¹æ³•**ï¼š

    + **æ•°å­¦åˆ†æ**ï¼š

      å‡è®¾è¾“å…¥$X$ çš„ç»´åº¦æ˜¯$[b,s,h]$,  å‡å®š$h$ é•¿åº¦è®¾å®šä¸º 2048. å‚æ•°æƒé‡ $W$

      step1ï¼š è·å–`Q`,`K`,`V` çŸ©é˜µï¼š
      $$
      [Q,K,V] = X * W^T  \\
      [b,s,h] * [h,3h] = [b,s,3h]
      $$
      step2:  åˆ‡å¤´æ“ä½œï¼Œç»´åº¦å˜æ¢ã€‚
    
      â€‹           `num_heads` è®¾ç½® 16 , `head_dim` åˆ™ä¸º 128. å¯¹åº”ç»´åº¦ä¿¡æ¯å¦‚ä¸‹ï¼š
      $$
      Q : [b,num_{-}heads,s,head_{-}dim] \\
      K^T:[b,num_{-}heads,head_{-}dim,s] \\
      S : Q * K^T = [b,num_{-}heads,s,s]
      $$
    
    + **ä»£ç **
    
      ```python
      query, key, value = self.c_attn(hidden_states).split(self.split_size, dim=2)
      query = self._split_heads(query, self.num_heads, self.head_dim)  # å½“å‰tokenå¯¹åº”çš„query
      key = self._split_heads(key, self.num_heads, self.head_dim)  # å½“å‰tokenå¯¹åº”çš„key
      value = self._split_heads(value, self.num_heads, self.head_dim)  # å½“å‰tokenå¯¹åº”çš„value
      
      if layer_past is not None:
          past_key, past_value = layer_past  # KV Cache
          key = torch.cat((past_key, key), dim=-2)  # å°†å½“å‰tokençš„keyä¸å†å²çš„Kæ‹¼æ¥
          value = torch.cat((past_value, value), dim=-2)  # å°†å½“å‰tokençš„valueä¸å†å²çš„Væ‹¼æ¥
      
      if use_cache is True: 
          present = (key, value)     
      else:
          present = None
      ```
    
      å…¥å‚å£ï¼š
    
      ```python
      transformer_outputs = self.transformer(
                  input_ids,
                  past_key_values=past_key_values,
                  attention_mask=attention_mask,
                  token_type_ids=token_type_ids,
                  **kwargs)
      ```
    
       kv_cache ä»¥å…ƒç»„çš„å½¢å¼ï¼Œé€šè¿‡  `past_key_values` å­—æ®µä¼ é€’ã€‚å‡è®¾å°†åŸå§‹è¾“å…¥è¿›è¡Œçº¿æ€§å˜åŒ–ï¼ˆ`MLP`ï¼‰åï¼Œå°†è½¬åŒ–ç»“æœä¿å­˜åœ¨ `past_key_values`é‡Œ , ä¾¿æ˜¯ï¼ˆ`P-tuning V2`ï¼Œ`Prefix_tuning`ï¼‰.

  + **`MQA`æ–¹æ³•**ï¼š

     è®¾$[b,s,h=2048]$ï¼Œè€Œ`MQA`å®ç° `k`,`v` å…±äº«æœºåˆ¶ï¼ŒåŠæŠ•å½±çŸ©é˜µ$W$ ç»´åº¦å‘ç”Ÿå˜åŒ–ã€‚
    $$
    [Q,K,V] = X * W^T  \\
    [b,s,h] * [h, h + head_{-}dim + head_{-}dim] = [b,s,h + 2* (h/num_{-}heads)] \\
    Q : [b,16,s,128] \\
    K^T:[b,1,128,s] \\
    $$
    åœ¨è®¡ç®—æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œå…ˆå¯¹$K^T$ åšå¹¿æ’­ï¼Œå³å°†ä¸€ä¸ªå¤´çš„ $K$ å¤šå¤åˆ¶ $num_{-}heads$ å—ã€‚ 
    $$
    S : Q * K^T = [b,16,s,s]
    $$
    æ³¨æ„åˆ°MQAç”±äºå…±äº«äº†Kã€Vï¼Œå°†ä¼šå¯¼è‡´Attentionçš„å‚æ•°é‡å‡å°‘äº†å°†è¿‘ä¸€åŠï¼Œè€Œä¸ºäº†æ¨¡å‹æ€»å‚æ•°é‡çš„ä¸å˜ï¼Œé€šå¸¸ä¼šç›¸åº”åœ°å¢å¤§FFN/GLUçš„è§„æ¨¡ï¼Œè¿™ä¹Ÿèƒ½å¼¥è¡¥ä¸€éƒ¨åˆ†æ•ˆæœæŸå¤±ã€‚

    
    $$
    o_t=[o^{(1)}_t,o^{(2)}_t,â‹¯,o^{(h)}_t]  \\
    o^{(s)}_t=Attention(q^{(s)}_t,k_{â‰¤t},v_{â‰¤t}) \\
    â‰œ\frac{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_i^âŠ¤)v_i}{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_i^âŠ¤)}   \\
    q^{(s)}_i=x_iW^{(s)}_qâˆˆR^{d_k},W^{(s)}_qâˆˆR^{dÃ—d_k} \\
    k^{(s)}_i=x_iW^{(s)}_kâˆˆR^{d_k},W^{(s)}_kâˆˆR^{dÃ—d_k} \\
    v^{(s)}_i=x_iW^{(s)}_vâˆˆR^{d_v},W^{(s)}_vâˆˆR^{dÃ—d_v}
    $$
  
+ **`GQA` æ–¹æ³•:** 
  
  GQAçš„æ€æƒ³ä¹Ÿå¾ˆæœ´ç´ ï¼Œå®ƒå°±æ˜¯å°†æ‰€æœ‰Headåˆ†ä¸º$g$ä¸ªç»„ï¼ˆ$g$å¯ä»¥æ•´é™¤$â„$ï¼‰ï¼Œæ¯ç»„å…±äº«åŒä¸€å¯¹Kã€Vï¼Œç”¨æ•°å­¦å…¬å¼è¡¨ç¤ºä¸º:
  $$
  o_t=[o^{(1)}_t,o^{(2)}_t,â‹¯,o^{(h)}_t]  \\
    o^{(s)}_t=Attention(q^{(s)}_t,k_{â‰¤t}^{([sg/h])},v_{â‰¤t}^{([sg/h])}) \\
    â‰œ\frac{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_{i}^{([sg/h])_T})v_i^{([sg/h])}}{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_i^{([sg/h])_T})}   \\
    q^{(s)}_i=x_iW^{(s)}_qâˆˆR^{d_k},W^{(s)}_qâˆˆR^{dÃ—d_k} \\
    k^{([sg/h])}_i=x_iW^{([sg/h])}_kâˆˆR^{d_k},W^{([sg/h])}_kâˆˆR^{dÃ—d_k} \\
    v^{([sg/h])}_i=x_iW^{([sg/h])}_vâˆˆR^{d_v},W^{([sg/h])}_vâˆˆR^{dÃ—d_v}
  $$
  
  
  `GQA`æ˜¯`MHA`åˆ°`MQA`çš„è‡ªç„¶è¿‡æ¸¡ï¼Œå½“`g=h`æ—¶å°±æ˜¯`MHA`ï¼Œ`g=1`æ—¶å°±æ˜¯MQAï¼Œå½“`1<g<h`æ—¶ï¼Œå®ƒåªå°†KV Cacheå‹ç¼©åˆ° `g/h`ï¼Œå‹ç¼©ç‡ä¸å¦‚`MQA`ï¼Œä½†åŒæ—¶ä¹Ÿæä¾›äº†æ›´å¤§çš„è‡ªç”±åº¦ï¼Œæ•ˆæœä¸Šæ›´æœ‰ä¿è¯ã€‚
  
+ **`MLA`æ–¹æ³•ï¼š**
  
  é¦–å…ˆåˆ†æ`GQA`åœ¨æŠ•å½±ååšä»€ä¹ˆï¼Ÿé¦–å…ˆå®ƒå°†å‘é‡å¯¹åŠåˆ†ä¸ºä¸¤ä»½åˆ†åˆ«ä½œä¸ºKã€Vï¼Œç„¶åæ¯ä¸€ä»½åˆå‡åˆ†ä¸º  ğ‘” ä»½ï¼Œæ¯ä¸€ä»½å¤åˆ¶ â„/ğ‘” æ¬¡ï¼Œä»¥æ­¤æ¥â€œå‡‘â€å¤Ÿ h ä¸ªAttention Headæ‰€éœ€è¦çš„Kã€Vã€‚  ç”±äºåˆ†å‰²ã€å¤åˆ¶éƒ½æ˜¯ç®€å•çš„çº¿æ€§å˜æ¢ï¼Œæ‰€ä»¥`MLA`çš„æƒ³æ³•æ˜¯å°†è¿™äº›ç®€å•çš„çº¿æ€§å˜æ¢æ¢æˆä¸€èˆ¬çš„çº¿æ€§å˜æ¢ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„èƒ½åŠ›ã€‚å³ï¼šé€šè¿‡ä¸åŒçš„æŠ•å½±çŸ©é˜µå†æ¬¡è®©æ‰€æœ‰çš„Kã€V Headéƒ½å˜å¾—å„ä¸ç›¸åŒã€‚
  $$
  o_t=[o^{(1)}_t,o^{(2)}_t,â‹¯,o^{(h)}_t]  \\
    o^{(s)}_t=Attention(q^{(s)}_t,k^{(s)}_{â‰¤t},v^{(s)}_{â‰¤t}) \\
    â‰œ\frac{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_i^{(s)_T})v_i^{(s)}}{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_i^{(s)_T})}   \\
    q^{(s)}_i=x_iW^{(s)}_qâˆˆR^{d_k},W^{(s)}_qâˆˆR^{dÃ—d_k} \\
    k^{(s)}_i=c_iW^{(s)}_kâˆˆR^{d_k},W^{(s)}_kâˆˆR^{d_cÃ—d_k} \\
    v^{(s)}_i=c_iW^{(s)}_vâˆˆR^{d_v},W^{(s)}_vâˆˆR^{d_cÃ—d_v} \\
    c_i=x_iW_câˆˆR^{d_c},W_câˆˆR^{dÃ—d_c}
  $$
  
  

**æŠ€å·§1**: **æ’ç­‰å˜åŒ–**
$$
q_i^{(s)} * k_i^{(s)T} =   (x_tW^{(s)}_q)(c_iW^{(s)}_k)^âŠ¤=x_t(W^{(s)}_q.W^{(s)T}_{k})c^âŠ¤_i
$$
  å³$W_k$ è¢« $W_q$ å¸å…¥ï¼ŒåŒç†$W_v$ è¢« $W_o$ å¸å…¥ã€‚ä¹Ÿå°±æ˜¯è¯´æ­¤æ—¶KV Cacheåªéœ€è¦å­˜ä¸‹æ‰€æœ‰çš„$c_i$å°±è¡Œï¼Œè€Œä¸è‡³äºå­˜ä¸‹æ‰€æœ‰çš„$k_i^{(s)}$, $v_i^{(s)}$ã€‚ å…¶å®å°±æ˜¯é€šè¿‡ä½ç§©åˆ†è§£ï¼Œå‹ç¼©KV Cacheï¼Œé€šè¿‡ä¸åŒçš„æŠ•å½±çŸ©é˜µç›¸å½“äºå¢å¼ºäº†GQAçš„èƒ½åŠ›ã€‚

**ç¼ºç‚¹ï¼š**ä¸å…¼å®¹`RoPE` æ—‹è½¬ä½ç½®ç¼–ç ï¼ŒçŸ©é˜µä¹˜æ³•ä¸æ»¡è¶³äº¤æ¢å¾‹.
$$
  q^{(s)}_i=x_iW^{(s)}_q\mathbb{R}_i \\
  k^{(s)}_i=c_iW^{(s)}_k\mathbb{R}_i \\
  q^{(s)}_ik^{(s)_T}_j = (x_iW^{(s)}_q\mathbb{R}_i)(c_jW^{(s)}_k\mathbb{R}_j)^T = x_i(W^{(s)}_q\mathbb{R}_{i-j}k^{(s)_T})c_i^T
$$
  è§£å†³æ–¹æ¡ˆï¼š **ç»´åº¦æ‹¼æ¥**, æ¯ä¸ªAttention Headçš„Qã€Kæ–°å¢$ğ‘‘ğ‘Ÿ$ä¸ªç»´åº¦ç”¨æ¥æ·»åŠ RoPEï¼Œå…¶ä¸­Kæ–°å¢çš„ç»´åº¦æ¯ä¸ªHeadå…±äº«ï¼š

**query embbeding = [token_emb; pos_emb]**
$$
  o_t=[o^{(1)}_t,o^{(2)}_t,â‹¯,o^{(h)}_t]  \\
  o^{(s)}_t=Attention(q^{(s)}_t,k^{(s)}_{â‰¤t},v^{(s)}_{â‰¤t}) \\
  â‰œ\frac{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_i^{(s)_T})v_i^{(s)}}{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_i^{(s)_T})}   \\
  q^{(s)}_i=[x_iW^{(s)}_{qc},x_iW^{(s)}_{qr}\mathbb{R}_i]âˆˆR^{d_k+d_r},W^{(s)}_{qc}âˆˆR^{dÃ—d_k}, W^{(s)}_{qr}âˆˆR^{dÃ—d_r}\\
  k^{(s)}_i=[x_iW^{(s)}_{kc},x_iW_{kr}\mathbb{R}_i]âˆˆR^{d_k+d_r},W^{(s)}_{kc}âˆˆR^{dÃ—d_k}, W^{(s)}_{kr}âˆˆR^{dÃ—d_r} \\
  v^{(s)}_i=c_iW^{(s)}_vâˆˆR^{d_v},W^{(s)}_vâˆˆR^{d_cÃ—d_v} \\
  c_i=x_iW_câˆˆR^{d_c},W_câˆˆR^{dÃ—d_c}
$$

  


![](./assets/kv_cache/MLA.png)

åœ¨æ¨ç†æ—¶KV Cacheåªéœ€è¦å­˜$c_i$ï¼Œæ–°å¢çš„å¸¦RoPEçš„ç»´åº¦å°±å¯ä»¥ç”¨æ¥è¡¥å……ä½ç½®ä¿¡æ¯ï¼Œå¹¶ä¸”ç”±äºæ‰€æœ‰Headå…±äº«ï¼Œæ‰€ä»¥ä¹Ÿå°±åªæœ‰åœ¨K Cacheè¿™é‡Œå¢åŠ äº†$d_r$ä¸ªç»´åº¦ã€‚

æ¨ç†é˜¶æ®µæœ€ç»ˆè¡¨ç°å½¢å¼ï¼š
$$
  o_t=[o^{(1)}_tW_v^{(1)},o^{(2)}_tW_v^{(2)},â‹¯,o^{(h)}_tW_v^{(h)}]  \\
  o^{(s)}_t=Attention(q^{(s)}_t,k^{(s)}_{â‰¤t},v^{(s)}_{â‰¤t}) \\
  â‰œ\frac{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_i^{(s)_T})v_i^{(s)}}{âˆ‘_{iâ‰¤t}exp(q^{(s)}_tk_i^{(s)_T})}   \\
  q^{(s)}_i=[c_i^{'}W^{(s)}_{qc}W^{(s)_T}_{kc},c_i^{'}W^{(s)}_{qr}\mathbb{R}_i]âˆˆR^{d_c+d_r} \\
  k^{(s)}_i=[c_i,x_iW_{kr}\mathbb{R}_i]âˆˆR^{d_c+d_r} \\
  
  W^{(s)}_{qc}âˆˆR^{d_c^{'}Ã—d_k},W^{(s)}_{kc}âˆˆR^{d_cÃ—d_k},W^{(s)}_{qr}âˆˆR^{d_c^{'}Ã—d_r},W_{kr}âˆˆR^{dÃ—d_r} \\
  
  c_i^{'}=x_iW_c^{'}âˆˆR^{d_c^{'}},W_câˆˆR^{dÃ—d_c^{'}} \\
  c_i=x_iW_câˆˆR^{d_c},W_câˆˆR^{dÃ—d_c}
$$

  

  




â€‹		



â€‹       









